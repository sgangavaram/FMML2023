{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhpKU2UlGpvrFPdKKh7unz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgangavaram/FMML2023/blob/LAB-2/Module_01_Lab_02_MLPractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "rng = np.random.default_rng(seed=42)"
      ],
      "metadata": {
        "id": "EhezM_56Zvd6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " dataset =  datasets.fetch_california_housing()\n",
        " dataset.target = dataset.target.astype(np.int)\n",
        " print(dataset.data.shape)\n",
        " print(dataset.target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNxX7Q8laexj",
        "outputId": "3631b150-f452-45cb-bba7-a7f0540513a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8)\n",
            "(20640,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-0c77f8e533aa>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dataset.target = dataset.target.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "  diff  = traindata - query\n",
        "  sq = diff*diff\n",
        "  dist = sq.sum(1)\n",
        "  label = trainlabel[np.argmin(dist)]\n",
        "  return label\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "  predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "  return predlabel"
      ],
      "metadata": {
        "id": "3hePtumzalrk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomClassifier(traindata, trainlabel, testdata):\n",
        "  classes = np.unique(trainlabel)\n",
        "  rints = rng.integers(low=0, high=len(classes), size=len(testdata))\n",
        "  predlabel = classes[rints]\n",
        "  return predlabel"
      ],
      "metadata": {
        "id": "_B03hHEoa0Ro"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy(gtlabel, predlabel):\n",
        "  assert len(gtlabel)==len(predlabel), \"Length of the groundtruth labels and predicted labels should be the same\"\n",
        "  correct = (gtlabel==predlabel).sum()\n",
        "  return correct/len(gtlabel)"
      ],
      "metadata": {
        "id": "i3mcVtTza6HU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(data, label, percent):\n",
        "  rnd = rng.random(len(label))\n",
        "  split1 = rnd<percent\n",
        "  split2 = rnd>=percent\n",
        "  split1data = data[split1,:]\n",
        "  split1label = label[split1]\n",
        "  split2data = data[split2,:]\n",
        "  split2label = label[split2]\n",
        "  return split1data, split1label, split2data, split2label"
      ],
      "metadata": {
        "id": "WEyYB9y0bAEA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata, testlabel, alltraindata, alltrainlabel = split(dataset.data, dataset.target, 20/100)\n",
        "print('Number of test samples = ', len(testlabel))\n",
        "print('Number of other samples = ', len(alltrainlabel))\n",
        "print('Percent of test data = ', len(testlabel)*100/len(dataset.target),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9yGJIQTbFK5",
        "outputId": "5c475471-e4e9-4379-bdd5-dd32f0a02023"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test samples =  4144\n",
            "Number of other samples =  16496\n",
            "Percent of test data =  20.07751937984496 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 90/100)"
      ],
      "metadata": {
        "id": "21Bv-0T5aXrq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainpred = NN(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using nearest neighbour is \", trainAccuracy)\n",
        "\n",
        "trainpred = RandomClassifier(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using random classifier is \", trainAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsX-E8dHbZmU",
        "outputId": "a034d24a-b0b6-42c6-9835-d4c704fa5190"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy using nearest neighbour is  1.0\n",
            "Train accuracy using random classifier is  0.16623292127521144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour is \", valAccuracy)\n",
        "\n",
        "valpred = RandomClassifier(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using random classifier is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKDTPRYvbh9M",
        "outputId": "06661d88-2ea6-457d-bf07-42992668d4aa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour is  0.3457142857142857\n",
            "Validation accuracy using random classifier is  0.1738095238095238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 75/100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy of nearest neighbour is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yf_LFoUbnS5",
        "outputId": "b3fc51e0-1c07-4b61-c9a4-8ff4cd5cd6ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy of nearest neighbour is  0.3439306358381503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "print('Test accuracy is ', testAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "679H0LGtb4TV",
        "outputId": "bb0e0ed4-fdf4-42ea-e990-3bac1db826d7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is  0.34917953667953666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 40/100)"
      ],
      "metadata": {
        "id": "VoJ7k6R4dqFL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainpred = NN(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using nearest neighbour is \", trainAccuracy)\n",
        "\n",
        "trainpred = RandomClassifier(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using random classifier is \", trainAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqHLeVkGduX9",
        "outputId": "0e727168-62c1-44c6-db00-36e4d47a2367"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy using nearest neighbour is  1.0\n",
            "Train accuracy using random classifier is  0.15995059441099274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour is \", valAccuracy)\n",
        "\n",
        "valpred = RandomClassifier(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using random classifier is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HimF1REbdyRG",
        "outputId": "a64a43e5-9af4-4695-a171-10e160229c59"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour is  0.3213893602155904\n",
            "Validation accuracy using random classifier is  0.16877931929334264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 75/100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy of nearest neighbour is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxwuNYgHd2uI",
        "outputId": "a9dfed7c-faef-4542-e0da-e0c5c8537f6e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy of nearest neighbour is  0.3448787728847105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "print('Test accuracy is ', testAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VltW6cgNd6Sg",
        "outputId": "777fa86f-85bf-474c-cddd-3c01415f84cc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is  0.34917953667953666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.How is the accuracy of the validation set affected if we increase the percentage of validation set? What happens when we reduce it?\n",
        "\n",
        "2.How does the size of the train and validation set affect how well we can predict the accuracy on the test set using the validation set?\n",
        "\n",
        "3.What do you think is a good percentage to reserve for the validation set so that thest two factors are balanced?"
      ],
      "metadata": {
        "id": "b_KkJd1hZcm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. By increasing and decreasing as shown above, the values are almost same. We notice that the accuracy is different for each run, but close together.  When you increase the percentage of the validation set, you provide the model with more data for evaluation. This can lead to a more accurate estimation of the model's generalization performance as it faces a larger, more diverse set of validation examples. Reducing the validation set size allows more data for training, which can improve training accuracy. However, a smaller validation set may not provide a reliable indicator of the model's ability to generalize to new, unseen data, increasing the risk of overfitting.\n",
        "\n",
        "2. The size of the training and validation set affects the reliability of the prediction of the accuracy of the test set using the validation set. A larger training set can yield a well-trained model but less computationally complex generalization. Conversely, a larger validation set provides more reliable analysis but may constrain the training data. Striking a balance between the two allows the model to capture the data structure and to be a reliable indicator of general applicability, improving the accuracy of the test system performance predictions\n",
        "\n",
        "3. 80 is test accuracy and 20 is validation"
      ],
      "metadata": {
        "id": "fRAMW_hBaBXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "\n",
        "1.Does averaging the validation accuracy across multiple splits give more consistent results?\n",
        "\n",
        "2.Does it give more accurate estimate of test accuracy?\n",
        "\n",
        "3.What is the effect of the number of iterations on the estimate? Do we get a better estimate with higher iterations?\n",
        "\n",
        "4.Consider the results you got for the previous questions. Can we deal with a very small train dataset or validation dataset by increasing the iterations?"
      ],
      "metadata": {
        "id": "aqdRHQVfVYlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. When we calculate the validation accuracy using techniques, like k cross validation it leads to more reliable and consistent results. This is because it reduces the impact of random data splits by providing performance estimates on subsets of data. By doing we get a comprehensive understanding of how well our model generalizes and it helps address issues related to imbalanced or outlier data.\n",
        "This method is particularly helpful when fine tuning hyperparameters as it allows us to test settings across partitions of our data. However keep in mind that the computational cost increases as we increase the number of folds (k). So it's important to choose a value for k based on your size and available resources. To summarize incorporating averages, from splits improves the reliability and credibility of evaluating our model."
      ],
      "metadata": {
        "id": "HtNxqdjnVm8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. To get an idea of how a model can perform on new data it's more reliable to calculate the average validation accuracy using techniques, like k fold cross validation. This method boosts confidence in the models performance within the dataset used for training and validation. However it doesn't directly give us an estimate of test accuracy, which is measured on a separate dataset that hasn't been seen before. Test accuracy remains the benchmark for evaluating how effectively the model will work in real world situations. Cross validation helps fine tune hyperparameters. Assess generalization tendencies, within the training data. It doesn't replace the need to accurately measure real world performance through true test accuracy.\n"
      ],
      "metadata": {
        "id": "6CLN6wqFXarr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. In general, increasing the number of iterations can lead to a better estimate, but there are diminishing returns, and it may not always be practical or necessary to use a very large number of iterations.The effect of the number of iterations on the estimate varies depending on the specific problem and algorithm. It's essential to strike a balance between computational resources, model performance, and the risk of overfitting when deciding how many iterations to use. In many cases, you may need to experiment with different iteration counts to find the optimal balance for your particular task."
      ],
      "metadata": {
        "id": "w2VFTSyaXo60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. While increasing the number of iterations can improve model performance on a small set of training data to some extent, it is not a panacea. To effectively address the challenges of small data sets, resulting in high iterative changes, it is important to consider a combination of strategies including data enhancement, regularity, and sampling including careful selection."
      ],
      "metadata": {
        "id": "eWn8SiKnhA1k"
      }
    }
  ]
}